import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import re
import matplotlib.font_manager as fm
import os

st.set_page_config(
    page_title="FC Manager",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "df" not in st.session_state:
    st.session_state.df = None

# ì‚¬ì´ë“œë°” í—¤ë”
st.sidebar.header("ì„¤ì •")

# í•œê¸€ í°íŠ¸ ì„¤ì • ì„ íƒ ë¼ë””ì˜¤ ë²„íŠ¼
font_option = st.sidebar.radio(
    "OS ì„ íƒ",
    ('Windows : Malgun Gothic', 'MAC : AppleGothic')
)

if font_option == 'Windows : Malgun Gothic':
    plt.rcParams['font.family'] = 'Malgun Gothic'
else:
    plt.rcParams['font.family'] = 'AppleGothic'

plt.rcParams['axes.unicode_minus'] = False

# í°íŠ¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
if font_option == 'Windows : Malgun Gothic':
    font_path = os.path.join(os.path.dirname(__file__), 'Fonts', 'malgun.ttf')  # Windows
else:
    font_path = os.path.join(os.path.dirname(__file__), 'Fonts', 'AppleGothic.ttf')  # Mac

# í°íŠ¸ íŒŒì¼ ë¡œë“œ
fontprop = fm.FontProperties(fname=font_path)
plt.rcParams['font.family'] = fontprop.get_name()
plt.rcParams['axes.unicode_minus'] = False

# ì¡°ì‚¬ ì¢…ë¥˜ ì„ íƒ
survey_option = st.sidebar.radio(
    "í•­ëª© ì„ íƒ",
    ('ë°ì¼ë¦¬ ë§Œì¡±ë„ ì¡°ì‚¬ ì¶”ì´ ë¶„ì„', 'ì •ì„± í‰ê°€ ê°ì • ë¶„ì„')
)

# ë°ì¼ë¦¬ ë§Œì¡±ë„ ì¡°ì‚¬ í™”ë©´
if survey_option == 'ë°ì¼ë¦¬ ë§Œì¡±ë„ ì¡°ì‚¬ ì¶”ì´ ë¶„ì„':
    # Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª©
    st.title("Daily ë§Œì¡±ë„ ì¡°ì‚¬ ë³€í™” ì¶”ì´ ë¶„ì„")

    # ì‚¬ìš©ìì—ê²Œ Google Sheets ë§í¬ë¥¼ ì…ë ¥ë°›ëŠ” í…ìŠ¤íŠ¸ ë°•ìŠ¤
    sheet_url = st.text_input("Google Sheets ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    sheet_url_btn = st.button("Enter")

    # í…ìŠ¤íŠ¸ ë°•ìŠ¤ì— URLì´ ì…ë ¥ë˜ì—ˆì„ ë•Œë§Œ ì‹¤í–‰
    if sheet_url and sheet_url_btn:
        try:
            # Google Sheets ë§í¬ì—ì„œ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID ì¶”ì¶œ
            match = re.search(r"/d/([a-zA-Z0-9-_]+)", sheet_url)
            if not match:
                raise ValueError("ìœ íš¨í•œ Google Sheets ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            sheet_id = match.group(1)

            # Google Sheets ë§í¬ë¥¼ CSV í˜•ì‹ì˜ export ë§í¬ë¡œ ë³€í™˜
            csv_export_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv"

            # ë°ì´í„° í”„ë ˆì„ ìƒì„±
            st.session_state.df = pd.read_csv(csv_export_url)

        except Exception as e:
            st.error(f"Google Sheetsì™€ ì—°ê²°í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

    # ë°ì´í„° í”„ë ˆì„ì´ ì„¸ì…˜ ìƒíƒœì— ì¡´ì¬í•  ë•Œë§Œ ì‹¤í–‰
    if st.session_state.df is not None:
        df = st.session_state.df

        # ë ˆì´ì•„ì›ƒ ë¶„í• 
        col1, col2 = st.columns([1, 4])  # ì™¼ìª½ê³¼ ì˜¤ë¥¸ìª½ ì—´ì˜ ë¹„ìœ¨ì„ 1:4ë¡œ ì„¤ì •

        with col1:
            # ë¼ë””ì˜¤ ë²„íŠ¼ê³¼ ì²´í¬ë°•ìŠ¤ ìƒì„±
            x_column = st.radio("X Labelì„ ìœ„í•œ ì»¬ëŸ¼ ì„ íƒ (ë‚ ì§œê°€ ìˆëŠ” ì»¬ëŸ¼ ì„ íƒ):", df.columns.tolist())
            y_columns = st.multiselect("Y Labelì„ ìœ„í•œ ì»¬ëŸ¼ ì„ íƒ (ì •ëŸ‰ í‰ê°€ ìˆ˜ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ ì„ íƒ):", df.columns.tolist())

            # ë°ì´í„° í”„ë ˆì„ ì¶œë ¥
            st.write("Google Sheets ë°ì´í„°:")
            st.dataframe(df)

        with col2:
            # ê·¸ë˜í”„ ìƒì„±
            if x_column and y_columns:
                grouped_df = df.groupby(x_column)[y_columns].mean()

                fig, ax = plt.subplots(figsize=(18, 12))
                grouped_df.plot(kind='bar', ax=ax)

                # ìˆ˜ì¹˜ ê°’ í…ìŠ¤íŠ¸ë¡œ í‘œê¸°
                for p in ax.patches:
                    ax.annotate(f'{p.get_height():.2f}', (p.get_x() + p.get_width() / 2., p.get_height()),
                                ha='center', va='center', fontsize=20, color='black', xytext=(0, 10),
                                textcoords='offset points')

                ax.set_xlabel("ë‚ ì§œ", fontsize=20)
                ax.set_ylabel("í‰ê·  ê°’", fontsize=20)
                ax.set_title(f"ë°ì¼ë¦¬ ë§Œì¡±ë„ ì¡°ì‚¬ ë³€ë™ ì¶”ì´", fontsize=20)

                # x label ê°€ë¡œ ì •ë ¬
                ax.set_xticklabels(ax.get_xticklabels(), rotation=0, fontsize=10)

                # y label í°íŠ¸ í¬ê¸° ì„¤ì •
                ax.tick_params(axis='y', labelsize=20)

                # ë²”ë¡€ í°íŠ¸ í¬ê¸° ì„¤ì •
                ax.legend(fontsize=16, loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=len(y_columns))

                st.pyplot(fig)


# # ì •ì„± í‰ê°€ ë¶„ì„ í™”ë©´
# elif survey_option == 'ì •ì„± í‰ê°€ ê°ì • ë¶„ì„':
#     st.title("ì •ì„± í‰ê°€ ê°ì • ë¶„ì„")

#     # ì‚¬ìš©ìì—ê²Œ Google Sheets ë§í¬ë¥¼ ì…ë ¥ë°›ëŠ” í…ìŠ¤íŠ¸ ë°•ìŠ¤
#     sheet_url_qual = st.text_input("Google Sheets ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
#     sheet_url_btn_qual = st.button("Enter")

#     # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
#     if "df_qual" not in st.session_state:
#         st.session_state.df_qual = None

#     # í…ìŠ¤íŠ¸ ë°•ìŠ¤ì— URLì´ ì…ë ¥ë˜ì—ˆì„ ë•Œë§Œ ì‹¤í–‰
#     if sheet_url_qual and sheet_url_btn_qual:
#         try:
#             # Google Sheetsì™€ ì—°ê²° ìƒì„±
#             conn_qual = st.connection("gsheets", type=GSheetsConnection, url=sheet_url_qual)

#             # ë°ì´í„° í”„ë ˆì„ ì½ê¸°
#             st.session_state.df_qual = conn_qual.read()

#         except Exception as e:
#             st.error(f"Google Sheetsì™€ ì—°ê²°í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

#     # ë°ì´í„° í”„ë ˆì„ì´ ì„¸ì…˜ ìƒíƒœì— ì¡´ì¬í•  ë•Œë§Œ ì‹¤í–‰
#     if st.session_state.df_qual is not None:
#         df_qual = st.session_state.df_qual

#         # ë°ì´í„° í”„ë ˆì„ ì¶œë ¥
#         st.write("Google Sheets ë°ì´í„°:")
#         st.dataframe(df_qual)

#         # ê°ì • ë¶„ì„ì„ ìœ„í•œ ì»¬ëŸ¼ ì„ íƒ
#         columns_list = [""] + df_qual.columns.tolist()
#         text_column = st.radio("ê°ì • ë¶„ì„ì„ ìœ„í•œ ì»¬ëŸ¼ ì„ íƒ:", columns_list)

#         if text_column:
#             if text_column != "":
#                 # ëª¨ë“  ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
#                 df_qual[text_column] = df_qual[text_column].astype(str)

#                 # BERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
#                 tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')
#                 model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)
                
#                 # GPU ì‚¬ìš© ì„¤ì •
#                 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                
#                 # í•™ìŠµëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ë¡œë“œ (CPU ì‚¬ìš© ì‹œ map_location ì„¤ì •)
#                 state_dict = torch.load('trained_model.pth', map_location=device)
                
#                 # ìƒˆë¡œìš´ ëª¨ë¸ì˜ state_dictë¥¼ ê°€ì ¸ì˜¤ê¸°
#                 new_state_dict = model.state_dict()

#                 # í•™ìŠµëœ ëª¨ë¸ì˜ state_dictë¥¼ ìƒˆ ëª¨ë¸ë¡œ ì˜®ê¸°ê¸° (ì„ë² ë”© ë ˆì´ì–´ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ íŒŒë¼ë¯¸í„°ë§Œ)
#                 for name, param in state_dict.items():
#                     if name in new_state_dict and param.size() == new_state_dict[name].size():
#                         new_state_dict[name].copy_(param)

#                 model.load_state_dict(new_state_dict)
                
#                 model.to(device)

#                 # ë°ì´í„°ì…‹ ì •ì˜
#                 class TextDataset(Dataset):
#                     def __init__(self, texts, tokenizer, max_len):
#                         self.texts = texts
#                         self.tokenizer = tokenizer
#                         self.max_len = max_len

#                     def __len__(self):
#                         return len(self.texts)

#                     def __getitem__(self, idx):
#                         text = self.texts[idx]
#                         encoding = self.tokenizer.encode_plus(
#                             text,
#                             add_special_tokens=True,
#                             max_length=self.max_len,
#                             return_token_type_ids=False,
#                             padding='max_length',
#                             return_attention_mask=True,
#                             return_tensors='pt',
#                             truncation=True,
#                         )

#                         return {
#                             'text': text,
#                             'input_ids': encoding['input_ids'].flatten(),
#                             'attention_mask': encoding['attention_mask'].flatten()
#                         }

#                 # ê°ì • ë¶„ì„ ìˆ˜í–‰ í•¨ìˆ˜
#                 def analyze_sentiment(texts):
#                     dataset = TextDataset(texts, tokenizer, max_len=128)
#                     dataloader = DataLoader(dataset, batch_size=32, shuffle=False)

#                     model.eval()
#                     sentiments = []
#                     with torch.no_grad():
#                         for batch in dataloader:
#                             input_ids = batch['input_ids'].to(device)
#                             attention_mask = batch['attention_mask'].to(device)

#                             outputs = model(input_ids, attention_mask=attention_mask)
#                             logits = outputs.logits
#                             predictions = torch.argmax(logits, dim=1)
#                             sentiments.extend(predictions.cpu().numpy())

#                     return ["ê¸ì •" if sentiment == 1 else "ë¶€ì •" for sentiment in sentiments]

#                 df_qual['ê°ì • ë¶„ì„ ê²°ê³¼'] = analyze_sentiment(df_qual[text_column].tolist())

#                 # ê²°ê³¼ ì¶œë ¥
#                 st.write("ê°ì • ë¶„ì„ ê²°ê³¼:")
#                 st.dataframe(df_qual[['ê°ì • ë¶„ì„ ê²°ê³¼'] + [text_column]])
